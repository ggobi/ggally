
R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ## test handing of weights and offset argument
> require(robustbase)
Loading required package: robustbase
> 
> ## generate simple example data
> data <- expand.grid(x1=letters[1:3], x2=LETTERS[1:4], rep=1:3)
> ## generate offset column
> data$os <- 1:nrow(data)
> set.seed(1)
> data$y <- data$os + rnorm(nrow(data))
> ## add collinear variables
> data$x3 <- rnorm(nrow(data))
> data$x4 <- rnorm(nrow(data))
> data$x5 <- data$x3 + data$x4
> ## add some NA terms
> data$y[1] <- NA
> data$x4[2:3] <- NA ## to test anova
> ## generate weights
> ## some obs with weight 0
> data$weights <- as.numeric(with(data, x1 != 'c' | (x2 != 'B' & x2 != 'C')))
> ## some obs with weight 2
> data$weights[data$x1 == 'b'] <- 2
> data2 <- rbind(subset(data, weights>0), subset(data, weights==2))
> 
> ## using these parameters we're essentially forcing lmrob() to
> ## fit a classic model --> easier to compare to lm()
> ctrl <- lmrob.control(psi="optimal", tuning.chi = 20, bb = 0.0003846154,
+                       tuning.psi=20, method="SM", cov=".vcov.w")
> 
> ## Classical models start with 'cm', robust just with  'rm' (or just 'm'):
> (cm0 <- lm   (y ~ x1*x2 + x3 + x4 + x5 + offset(os), data))

Call:
lm(formula = y ~ x1 * x2 + x3 + x4 + x5 + offset(os), data = data)

Coefficients:
(Intercept)          x1b          x1c          x2B          x2C          x2D  
    0.01008     -1.14140      0.48156      0.01357      0.86985      0.15178  
         x3           x4           x5      x1b:x2B      x1c:x2B      x1b:x2C  
   -0.01655     -0.02388           NA      1.05416     -0.32889      0.69954  
    x1c:x2C      x1b:x2D      x1c:x2D  
   -0.73949      1.08478     -1.31578  

> (cm1 <- lm   (y ~ x1*x2 + x3 + x4 + x5 + offset(os), data,  weights=weights))

Call:
lm(formula = y ~ x1 * x2 + x3 + x4 + x5 + offset(os), data = data, 
    weights = weights)

Coefficients:
(Intercept)          x1b          x1c          x2B          x2C          x2D  
  -0.002961    -1.132857     0.492904     0.017959     0.858031     0.208510  
         x3           x4           x5      x1b:x2B      x1c:x2B      x1b:x2C  
  -0.021632    -0.079147           NA     1.040529           NA     0.736944  
    x1c:x2C      x1b:x2D      x1c:x2D  
         NA     1.099090    -1.371953  

> (cm2 <- lm   (y ~ x1*x2 + x3 + x4 + x5,              data2, offset=os))

Call:
lm(formula = y ~ x1 * x2 + x3 + x4 + x5, data = data2, offset = os)

Coefficients:
(Intercept)          x1b          x1c          x2B          x2C          x2D  
  -0.002961    -1.132857     0.492904     0.017959     0.858031     0.208510  
         x3           x4           x5      x1b:x2B      x1c:x2B      x1b:x2C  
  -0.021632    -0.079147           NA     1.040529           NA     0.736944  
    x1c:x2C      x1b:x2D      x1c:x2D  
         NA     1.099090    -1.371953  

> (rm0 <- lmrob(y ~ x1*x2 + x3 + x4 + x5 + offset(os), data,                   control=ctrl))

Call:
lmrob(formula = y ~ x1 * x2 + x3 + x4 + x5 + offset(os), data = data, control = ctrl)
 \--> method = "MM"
Coefficients:
(Intercept)          x1b          x1c          x2B          x2C          x2D  
    0.01008     -1.14140      0.48156      0.01357      0.86985      0.15178  
         x3           x4           x5      x1b:x2B      x1c:x2B      x1b:x2C  
   -0.01655     -0.02388           NA      1.05416     -0.32889      0.69954  
    x1c:x2C      x1b:x2D      x1c:x2D  
   -0.73949      1.08478     -1.31578  

> set.seed(2)
> (rm1 <- lmrob(y ~ x1*x2 + x3 + x4 + x5 + offset(os), data,  weights=weights, control=ctrl))

Call:
lmrob(formula = y ~ x1 * x2 + x3 + x4 + x5 + offset(os), data = data, weights = weights,     control = ctrl)
 \--> method = "MM"
Coefficients:
(Intercept)          x1b          x1c          x2B          x2C          x2D  
  -0.002961    -1.132857     0.492904     0.017959     0.858031     0.208510  
         x3           x4           x5      x1b:x2B      x1c:x2B      x1b:x2C  
  -0.021632    -0.079147           NA     1.040529           NA     0.736944  
    x1c:x2C      x1b:x2D      x1c:x2D  
         NA     1.099090    -1.371953  

> set.seed(2)
> (rm2 <- lmrob(y ~ x1*x2 + x3 + x4 + x5,              data2, offset=os,       control=ctrl))

Call:
lmrob(formula = y ~ x1 * x2 + x3 + x4 + x5, data = data2, offset = os, control = ctrl)
 \--> method = "MM"
Coefficients:
(Intercept)          x1b          x1c          x2B          x2C          x2D  
  -0.002961    -1.132857     0.492904     0.017959     0.858031     0.208510  
         x3           x4           x5      x1b:x2B      x1c:x2B      x1b:x2C  
  -0.021632    -0.079147           NA     1.040529           NA     0.736944  
    x1c:x2C      x1b:x2D      x1c:x2D  
         NA     1.099090    -1.371953  

> 
> sc0 <- summary(cm0)
> sc1 <- summary(cm1)
> sc2 <- summary(cm2)
> (sr0 <- summary(rm0))

Call:
lmrob(formula = y ~ x1 * x2 + x3 + x4 + x5 + offset(os), data = data, control = ctrl)
 \--> method = "MM"
Residuals:
     Min       1Q   Median       3Q      Max 
-1.50524 -0.48219  0.01663  0.42714  1.59122 

Coefficients: (1 not defined because of singularities)
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.01008    0.76421   0.013    0.990
x1b         -1.14140    1.02228  -1.117    0.278
x1c          0.48156    1.01891   0.473    0.642
x2B          0.01357    0.95276   0.014    0.989
x2C          0.86985    0.94762   0.918    0.370
x2D          0.15178    0.99480   0.153    0.880
x3          -0.01655    0.22284  -0.074    0.942
x4          -0.02388    0.25629  -0.093    0.927
x5                NA         NA      NA       NA
x1b:x2B      1.05416    1.30705   0.807    0.430
x1c:x2B     -0.32889    1.30044  -0.253    0.803
x1b:x2C      0.69954    1.37279   0.510    0.616
x1c:x2C     -0.73949    1.30141  -0.568    0.577
x1b:x2D      1.08478    1.32102   0.821    0.422
x1c:x2D     -1.31578    1.33335  -0.987    0.336

Robust residual standard error: 1.007 
Multiple R-squared:  0.9933,	Adjusted R-squared:  0.9887 
Convergence in 1 IRWLS iterations

Robustness weights: 
 All 33 weights are ~= 1.
Algorithmic parameters: 
               bb        refine.tol           rel.tol         solve.tol 
        3.846e-04         1.000e-07         1.000e-07         1.000e-07 
      eps.outlier             eps.x warn.limit.reject warn.limit.meanrw 
        3.030e-03         4.369e-12         5.000e-01         5.000e-01 
     nResample     tuning.chi     tuning.psi         max.it       best.r.s 
           500             20             20             50              2 
      k.fast.s          k.max    maxit.scale      trace.lev            mts 
             1            200            200              0           1000 
    compute.rd fast.s.large.n 
             0           2000 
                  psi           subsampling                   cov 
            "optimal"         "nonsingular"             ".vcov.w" 
compute.outlier.stats 
                 "SM" 
seed : int(0) 
> (sr1 <- summary(rm1))

Call:
lmrob(formula = y ~ x1 * x2 + x3 + x4 + x5 + offset(os), data = data, weights = weights, 
    control = ctrl)
 \--> method = "MM"
Residuals:
     Min       1Q   Median       3Q      Max 
-1.52261 -0.57370 -0.07248  0.39247  1.61986 

Coefficients: (3 not defined because of singularities)
             Estimate Std. Error t value Pr(>|t|)
(Intercept) -0.002961   0.977109  -0.003    0.998
x1b         -1.132857   1.133342  -1.000    0.333
x1c          0.492904   1.297399   0.380    0.709
x2B          0.017959   1.213927   0.015    0.988
x2C          0.858031   1.204169   0.713    0.487
x2D          0.208510   1.275792   0.163    0.872
x3          -0.021632   0.284226  -0.076    0.940
x4          -0.079147   0.324629  -0.244    0.811
x5                 NA         NA      NA       NA
x1b:x2B      1.040529   1.443384   0.721    0.482
x1c:x2B            NA         NA      NA       NA
x1b:x2C      0.736944   1.530596   0.481    0.637
x1c:x2C            NA         NA      NA       NA
x1b:x2D      1.099090   1.461384   0.752    0.464
x1c:x2D     -1.371953   1.698858  -0.808    0.432

Robust residual standard error: 1.281 
Multiple R-squared:  0.9923,	Adjusted R-squared:  0.9866 
Convergence in 1 IRWLS iterations

Robustness weights: 
 6 observations c(3,6,15,18,27,30) are outliers with |weight| = 0 ( < 0.0037); 
 27 weights are ~= 1.
Algorithmic parameters: 
               bb        refine.tol           rel.tol         solve.tol 
        3.846e-04         1.000e-07         1.000e-07         1.000e-07 
      eps.outlier             eps.x warn.limit.reject warn.limit.meanrw 
        3.704e-03         5.094e-12         5.000e-01         5.000e-01 
     nResample     tuning.chi     tuning.psi         max.it       best.r.s 
           500             20             20             50              2 
      k.fast.s          k.max    maxit.scale      trace.lev            mts 
             1            200            200              0           1000 
    compute.rd fast.s.large.n 
             0           2000 
                  psi           subsampling                   cov 
            "optimal"         "nonsingular"             ".vcov.w" 
compute.outlier.stats 
                 "SM" 
seed : int(0) 
> (sr2 <- summary(rm2))

Call:
lmrob(formula = y ~ x1 * x2 + x3 + x4 + x5, data = data2, offset = os, control = ctrl)
 \--> method = "MM"
Residuals:
     Min       1Q   Median       3Q      Max 
-1.52261 -0.51773  0.06925  0.38640  1.61986 

Coefficients: (3 not defined because of singularities)
             Estimate Std. Error t value Pr(>|t|)
(Intercept) -0.002961   0.742168  -0.004    0.997
x1b         -1.132857   0.860835  -1.316    0.200
x1c          0.492904   0.985445   0.500    0.621
x2B          0.017959   0.922044   0.019    0.985
x2C          0.858031   0.914632   0.938    0.357
x2D          0.208510   0.969033   0.215    0.831
x3          -0.021632   0.215885  -0.100    0.921
x4          -0.079147   0.246574  -0.321    0.751
x5                 NA         NA      NA       NA
x1b:x2B      1.040529   1.096329   0.949    0.351
x1c:x2B            NA         NA      NA       NA
x1b:x2C      0.736944   1.162571   0.634    0.532
x1c:x2C            NA         NA      NA       NA
x1b:x2D      1.099090   1.110001   0.990    0.331
x1c:x2D     -1.371953   1.290375  -1.063    0.297

Robust residual standard error: 0.9728 
Multiple R-squared:  0.9923,	Adjusted R-squared:  0.989 
Convergence in 1 IRWLS iterations

Robustness weights: 
 All 38 weights are ~= 1.
Algorithmic parameters: 
               bb        refine.tol           rel.tol         solve.tol 
        3.846e-04         1.000e-07         1.000e-07         1.000e-07 
      eps.outlier             eps.x warn.limit.reject warn.limit.meanrw 
        2.632e-03         4.369e-12         5.000e-01         5.000e-01 
     nResample     tuning.chi     tuning.psi         max.it       best.r.s 
           500             20             20             50              2 
      k.fast.s          k.max    maxit.scale      trace.lev            mts 
             1            200            200              0           1000 
    compute.rd fast.s.large.n 
             0           2000 
                  psi           subsampling                   cov 
            "optimal"         "nonsingular"             ".vcov.w" 
compute.outlier.stats 
                 "SM" 
seed : int(0) 
> 
> ## test Estimates, Std. Errors, ...
> stopifnot(all.equal(coef(cm1), coef(cm2)),
+           all.equal(coef(rm1), coef(rm2)),
+           all.equal(coef(sc0), coef(sr0)),
+           all.equal(coef(sc1), coef(sr1)),
+           all.equal(coef(sc2), coef(sr2)))
> 
> ## test class "lm" methods that do not depend on weights
> meths1 <- c("family",
+             "formula",
+             "labels",
+             "model.matrix",
+             "na.action",
+             "terms")
> for (meth in meths1)
+     stopifnot(all.equal(do.call(meth, list(rm0)),
+                         do.call(meth, list(rm1))))
> 
> ## class "lm" methods that depend on weights
> ##                                      FIXME:
> meths2 <- c(#"AIC",
+             "alias",
+             #"BIC",
+             "case.names",
+             "coef",
+             "confint",
+             #"cooks.distance",
+             #"deviance",
+             "df.residual",
+             #"dfbeta",
+             #"dfbetas",
+             #"drop1",
+             "dummy.coef",
+             #"effects",
+             #"extractAIC",
+             #"hatvalues",
+             #"influence",
+             "kappa",
+             #"logLik",
+             #"model.frame", ## disable because of zero.weights attribute
+             "nobs",
+             "predict",
+                                         #"proj",
+                                         #"rstandard",
+                                         #"rstudent",
+                                         #"simulate",
+             ##"summary", ## see above
+             "variable.names",
+             ##"vcov",    ## see below
+             "weights")
> op <- options(warn = 1)# print immediately
> for (meth in meths2) {
+     cat(meth,":")
+     .SW. <- if(meth == "weights") suppressWarnings else identity # for suppressing
+     ## No weights defined for this object. Use type="robustness" ....
+     stopifnot(all.equal(do.call(meth, list(cm1)),
+                         do.call(meth, list(rm1))),
+               all.equal(do.call(meth, list(cm2)),
+ 		   .SW.(do.call(meth, list(rm2)))))
+ 
+     cat("\n")
+ }
alias :
case.names :
coef :
confint :
df.residual :
dummy.coef :
kappa :
nobs :
predict :
variable.names :
weights :
> options(op)# reverting
> 
> ## further tests:
> anova(rm1, update(rm1, ~ . - x4 - x5))
Robust Wald Test Table

Model 1: y ~ x1 * x2 + x3 + x4 + x5 + offset(os)
Model 2: y ~ x1 + x2 + x3 + x1:x2 + offset(os)
Largest model fitted by lmrob(), i.e. SM

  pseudoDf Test.Stat Df Pr(>chisq)
1       18                        
2       22  0.059442  1     0.8074
> anova(rm2, update(rm2, ~ . - x4 - x5))
Robust Wald Test Table

Model 1: y ~ x1 * x2 + x3 + x4 + x5
Model 2: y ~ x1 + x2 + x3 + x1:x2
Largest model fitted by lmrob(), i.e. SM

  pseudoDf Test.Stat Df Pr(>chisq)
1       23                        
2       27   0.10303  1     0.7482
> 
> stopifnot(all.equal(fitted(cm0),          fitted(rm0)),
+           all.equal(fitted(cm1),          fitted(rm1)),
+           ## FIXME?: fitted(cm2) is of class AsIs but fitted(rm2) is numeric
+           all.equal(unclass(fitted(cm2)), fitted(rm2)))
> 
> nd <- expand.grid(x1=letters[1:3], x2=LETTERS[1:4])
> set.seed(3)
> nd$x3 <- rnorm(nrow(nd))
> nd$x4 <- rnorm(nrow(nd))
> nd$x5 <- rnorm(nrow(nd))
> nd$os <- nrow(nd):1
> wts   <- runif(nrow(nd))
> stopifnot(all.equal(predict(cm0, nd, interval="prediction"),
+                     predict(rm0, nd, interval="prediction")),
+           all.equal(predict(cm1, nd, interval="prediction"),
+                     predict(rm1, nd, interval="prediction")),
+           all.equal(predict(cm2, nd, interval="prediction"),
+                     predict(rm2, nd, interval="prediction")),
+           all.equal(predict(cm0, nd, interval="prediction", weights=wts),
+                     predict(rm0, nd, interval="prediction", weights=wts)),
+           all.equal(predict(cm1, nd, interval="prediction", weights=wts),
+                     predict(rm1, nd, interval="prediction", weights=wts)),
+           all.equal(predict(cm2, nd, interval="prediction", weights=wts),
+                     predict(rm2, nd, interval="prediction", weights=wts),
+                     tolerance=1e-7))
There were 14 warnings (use warnings() to see them)
> 
> ## Padding can lead to differing values here
> ## so test only full rank part
> qrEQ <- function(m1, m2) {
+     q1 <- qr(m1)
+     q2 <- qr(m2)
+     r <- 1:q1$rank
+     stopifnot(q1$rank == q2$rank,
+               all.equal(q1$pivot, q2$pivot),
+               all.equal(q1$qraux[r],q2$qraux[r]),
+               all.equal(q1$qr[r,r], q2$qr[r,r]))
+ }
> qrEQ(cm0, rm0)
> qrEQ(cm1, rm1)
> qrEQ(cm2, rm2)
> 
> stopifnot(all.equal(residuals(cm0),                      residuals(rm0)),
+           all.equal(residuals(cm1),                      residuals(rm1)),
+           ## FIXME?: residuals(cm2) is of class AsIs but residuals(rm2) is numeric
+           all.equal(unclass(residuals(cm2)),             residuals(rm2)),
+           all.equal(resid(cm0, type="pearson"),          resid(rm0, type="pearson")),
+           all.equal(resid(cm1, type="pearson"),          resid(rm1, type="pearson")),
+           all.equal(unclass(resid(cm2, type="pearson")), resid(rm2, type="pearson")))
> 
> stopifnot(all.equal(vcov(cm0), vcov(rm0), check.attributes=FALSE),
+           all.equal(vcov(cm1), vcov(rm1), check.attributes=FALSE),
+           all.equal(vcov(cm2), vcov(rm2), check.attributes=FALSE))
> 
> ## Null fits (rank(X)==0) are tested in NAcoef.R
> 
> ## testing weight=0 bug
> lmrob(y ~ x3, data, weights=weights)

Call:
lmrob(formula = y ~ x3, data = data, weights = weights)
 \--> method = "MM"
Coefficients:
(Intercept)           x3  
    18.7474       0.1751  

> 
> proc.time()
   user  system elapsed 
  0.817   0.077   0.904 
